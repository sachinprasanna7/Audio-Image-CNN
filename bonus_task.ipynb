{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mirorred UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MirroredUNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MirroredUNet, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Decoder with mirrored skip connections\n",
    "        self.conv4 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.conv5 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.conv6 = nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2)\n",
    "\n",
    "        # Output convolution\n",
    "        self.output_conv = nn.Conv2d(32, 3, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x1 = F.relu(self.conv1(x))\n",
    "        x2 = self.pool1(x1)\n",
    "\n",
    "        x3 = F.relu(self.conv2(x2))\n",
    "        x4 = self.pool2(x3)\n",
    "\n",
    "        x5 = F.relu(self.conv3(x4))\n",
    "        x6 = self.pool3(x5)\n",
    "\n",
    "        # Decoder with mirrored skip connections\n",
    "        x7 = F.relu(self.conv4(x6, output_size=x5.shape))\n",
    "        x8 = F.relu(self.conv5(x7, output_size=x3.shape))\n",
    "        x9 = F.relu(self.conv6(x8, output_size=x1.shape))\n",
    "\n",
    "        # Output convolution\n",
    "        output = self.output_conv(x9)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Load the image\n",
    "img = cv2.imread('samp.png')\n",
    "\n",
    "# Convert BGR image to RGB\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Resize image to match the expected input shape of the model\n",
    "input_size = (256, 256)  # Assuming the model expects input size of 256x256\n",
    "img = cv2.resize(img, input_size)\n",
    "\n",
    "# Convert image to PyTorch tensor and normalize\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Assuming ImageNet normalization\n",
    "])\n",
    "img_tensor = transform(img).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "# Load the model\n",
    "model = MirroredUNet()\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Perform inference\n",
    "with torch.no_grad():\n",
    "    output_tensor = model(img_tensor)\n",
    "\n",
    "# Convert the output tensor to numpy array\n",
    "output_img = output_tensor.squeeze(0).permute(1, 2, 0).cpu().numpy()\n",
    "\n",
    "# Post-process the output image if needed (e.g., denormalization)\n",
    "# (Note: This step depends on how you preprocess your input and what normalization you apply)\n",
    "\n",
    "# Convert the output image to uint8 and ensure it's in the range [0, 255]\n",
    "output_img = np.clip(output_img * 255, 0, 255).astype(np.uint8)\n",
    "\n",
    "# Display or save the output image\n",
    "cv2.imshow('Output Image', cv2.cvtColor(output_img, cv2.COLOR_RGB2BGR))\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
